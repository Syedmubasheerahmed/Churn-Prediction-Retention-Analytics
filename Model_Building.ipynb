{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9371323c",
   "metadata": {},
   "source": [
    "##                                                    MODEL BUILDING & EVALUATION\n",
    "Build and compare multiple models to predict customer churn and identify the best-performing model for deployment.\n",
    "### Modeling Approach\n",
    "This notebook develops three different machine learning models to predict customer churn:\n",
    "* Logistic Regression - Baseline interpretable linear model\n",
    "* Random Forest - Ensemble model for capturing complex interactions\n",
    "* Gradient Boosting - Advanced ensemble technique for high-accuracy predictions\n",
    "### Evaluation Strategy\n",
    "* Accuracy, Precision, Recall, F1-Score\n",
    "* Confusion Matrix analysis\n",
    "* Feature importance rankings\n",
    "* Cross-validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02e2e40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libraries loaded\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, roc_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a42ae09",
   "metadata": {},
   "source": [
    "### 1,What dataset are we working with for model development?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61537539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 7043 rows × 21 columns\n",
      "\n",
      "Dataset info:\n",
      "  Customers: 7,043\n",
      "  Features: 21\n",
      "  Target: Churn (Yes/No)\n",
      "\n",
      "First 3 rows:\n",
      "____________________________________________________________________________________________________\n",
      "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
      "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
      "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
      "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
      "\n",
      "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
      "0  No phone service             DSL             No  ...               No   \n",
      "1                No             DSL            Yes  ...              Yes   \n",
      "2                No             DSL            Yes  ...               No   \n",
      "\n",
      "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
      "0          No          No              No  Month-to-month              Yes   \n",
      "1          No          No              No        One year               No   \n",
      "2          No          No              No  Month-to-month              Yes   \n",
      "\n",
      "      PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
      "0  Electronic check          29.85         29.85    No  \n",
      "1      Mailed check          56.95        1889.5    No  \n",
      "2      Mailed check          53.85        108.15   Yes  \n",
      "\n",
      "[3 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/Telco-Customer-Churn.csv')\n",
    "print(f\"Dataset loaded: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "print(f\"\\nDataset info:\")\n",
    "print(f\"  Customers: {len(df):,}\")\n",
    "print(f\"  Features: {df.shape[1]}\")\n",
    "print(f\"  Target: Churn (Yes/No)\")\n",
    "print(f\"\\nFirst 3 rows:\")\n",
    "print(\"_\" * 100)\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736b0cec",
   "metadata": {},
   "source": [
    "### 2,How do we prepare categorical variables for machine learning models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baa1b024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical variables encoded\n",
      "\n",
      "Churn distribution:\n",
      "  No (0): 5,174 customers\n",
      "  Yes (1): 1,869 customers\n",
      "\n",
      "Sample\n",
      "   gender  Contract  Churn\n",
      "0       0         0      0\n",
      "1       1         1      0\n",
      "2       1         0      1\n"
     ]
    }
   ],
   "source": [
    "df_model = df.copy()\n",
    "categorical_cols = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity','OnlineBackup', 'DeviceProtection', 'TechSupport','StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
    "\n",
    "# Convert each column\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    if col in df_model.columns:\n",
    "        le = LabelEncoder()\n",
    "        df_model[col] = le.fit_transform(df_model[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Convert variable (Churn: Yes=1, No=0)\n",
    "df_model['Churn'] = (df_model['Churn'] == 'Yes').astype(int)\n",
    "print(\"Categorical variables encoded\")\n",
    "print(f\"\\nChurn distribution:\")\n",
    "print(f\"  No (0): {(df_model['Churn'] == 0).sum():,} customers\")\n",
    "print(f\"  Yes (1): {(df_model['Churn'] == 1).sum():,} customers\")\n",
    "print(f\"\\nSample\")\n",
    "print(df_model[['gender', 'Contract', 'Churn']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850826a9",
   "metadata": {},
   "source": [
    "### 3,What features will we use to train the models, and how do we prepare them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8c46e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Missing values filled: 0\n",
      "\n",
      " Features and target prepared\n",
      "  Features (X): 7043 rows × 19 columns\n",
      "  Target (y): 7043 values\n",
      "\n",
      "Feature columns (19 total):\n",
      "  1. gender\n",
      "  2. SeniorCitizen\n",
      "  3. Partner\n",
      "  4. Dependents\n",
      "  5. tenure\n",
      "  6. PhoneService\n",
      "  7. MultipleLines\n",
      "  8. InternetService\n",
      "  9. OnlineSecurity\n",
      "  10. OnlineBackup\n",
      "  11. DeviceProtection\n",
      "  12. TechSupport\n",
      "  13. StreamingTV\n",
      "  14. StreamingMovies\n",
      "  15. Contract\n",
      "  16. PaperlessBilling\n",
      "  17. PaymentMethod\n",
      "  18. MonthlyCharges\n",
      "  19. TotalCharges\n"
     ]
    }
   ],
   "source": [
    "df_model['TotalCharges'] = pd.to_numeric(df_model['TotalCharges'], errors='coerce')\n",
    "\n",
    "# Filling missing values with median\n",
    "df_model['TotalCharges'].fillna(df_model['TotalCharges'].median(), inplace=True)\n",
    "print(f\"  Missing values filled: {df_model['TotalCharges'].isnull().sum()}\")\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df_model.drop(['customerID', 'Churn'], axis=1, errors='ignore')\n",
    "y = df_model['Churn']\n",
    "\n",
    "print(f\"\\n Features and target prepared\")\n",
    "print(f\"  Features (X): {X.shape[0]} rows × {X.shape[1]} columns\")\n",
    "print(f\"  Target (y): {y.shape[0]} values\")\n",
    "print(f\"\\nFeature columns ({X.shape[1]} total):\")\n",
    "for i, col in enumerate(X.columns, 1):\n",
    "    print(f\"  {i}. {col}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92903704",
   "metadata": {},
   "source": [
    "### 4,How do we split the data to train and evaluate our models fairly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c982021c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set:\n",
      "  Samples: 5,634\n",
      "  Churned: 1,495 (26.5%)\n",
      "  Retained: 4,139 (73.5%)\n",
      "\n",
      "Test set:\n",
      "  Samples: 1,409\n",
      "  Churned: 374 (26.5%)\n",
      "  Retained: 1,035 (73.5%)\n"
     ]
    }
   ],
   "source": [
    "#(80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"\\nTraining set:\")\n",
    "print(f\"  Samples: {len(X_train):,}\")\n",
    "print(f\"  Churned: {y_train.sum():,} ({y_train.mean():.1%})\")\n",
    "print(f\"  Retained: {(y_train == 0).sum():,} ({(y_train == 0).mean():.1%})\")\n",
    "\n",
    "print(f\"\\nTest set:\")\n",
    "print(f\"  Samples: {len(X_test):,}\")\n",
    "print(f\"  Churned: {y_test.sum():,} ({y_test.mean():.1%})\")\n",
    "print(f\"  Retained: {(y_test == 0).sum():,} ({(y_test == 0).mean():.1%})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070714e3",
   "metadata": {},
   "source": [
    "### 5,How does Logistic Regression perform as our baseline churn prediction model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1d3f972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 1: LOGISTIC REGRESSION\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "\n",
      "Model trained on 5,634 customers\n",
      "Tested on 1,409 customers\n",
      "\n",
      "AUC-ROC Score: 0.8408\n",
      "  (0.50 = random guess, 1.00 = perfect)\n",
      "\n",
      "Confusion Matrix:\n",
      " ---------------Predicted\n",
      " ---------- No (0)  Yes (1)\n",
      "No       918     117\n",
      "Yes      166     208\n",
      "\n",
      "Detailed Metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Retained (0)       0.85      0.89      0.87      1035\n",
      " Churned (1)       0.64      0.56      0.60       374\n",
      "\n",
      "    accuracy                           0.80      1409\n",
      "   macro avg       0.74      0.72      0.73      1409\n",
      "weighted avg       0.79      0.80      0.79      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MODEL 1: LOGISTIC REGRESSION\")\n",
    "print(\"|\" * 60)\n",
    "\n",
    "# Train\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "lr_pred_prob = lr_model.predict_proba(X_test)[:, 1]  # Probability of churn\n",
    "lr_pred = lr_model.predict(X_test)  # Actual prediction (0 or 1)\n",
    "\n",
    "# Evaluate performance\n",
    "lr_auc = roc_auc_score(y_test, lr_pred_prob)\n",
    "print(f\"\\nModel trained on {len(X_train):,} customers\")\n",
    "print(f\"Tested on {len(X_test):,} customers\")\n",
    "print(f\"\\nAUC-ROC Score: {lr_auc:.4f}\")\n",
    "print(f\"  (0.50 = random guess, 1.00 = perfect)\")\n",
    "\n",
    "# Show confusion matrix\n",
    "cm = confusion_matrix(y_test, lr_pred)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\" ---------------Predicted\")\n",
    "print(f\" ---------- No (0)  Yes (1)\")\n",
    "print(f\"No     {cm[0,0]:5}   {cm[0,1]:5}\")\n",
    "print(f\"Yes    {cm[1,0]:5}   {cm[1,1]:5}\")\n",
    "\n",
    "# Detailed metrics\n",
    "print(f\"\\nDetailed Metrics\")\n",
    "print(classification_report(y_test, lr_pred, target_names=['Retained (0)', 'Churned (1)']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf94f49",
   "metadata": {},
   "source": [
    "### 6,Does Random Forest improve prediction performance over the Logistic Regression baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86f1a75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 2: RANDOM FOREST\n",
      "============================================================\n",
      "\n",
      "Model trained on 5,634 customers\n",
      "Tested on 1,409 customers\n",
      "\n",
      " AUC-ROC Score: 0.8357\n",
      "\n",
      "Confusion Matrix:\n",
      " --------------------Predicted\n",
      " ---------------- No (0)  Yes (1)\n",
      "Actual No       931     104\n",
      "Actual Yes      183     191\n",
      "\n",
      "Accuracy: 79.6%\n"
     ]
    }
   ],
   "source": [
    "print(\"MODEL 2: RANDOM FOREST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Train the model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "rf_pred_prob = rf_model.predict_proba(X_test)[:, 1]\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "# performance\n",
    "rf_auc = roc_auc_score(y_test, rf_pred_prob)\n",
    "print(f\"\\nModel trained on {len(X_train):,} customers\")\n",
    "print(f\"Tested on {len(X_test):,} customers\")\n",
    "print(f\"\\n AUC-ROC Score: {rf_auc:.4f}\")\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, rf_pred)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\" --------------------Predicted\")\n",
    "print(f\" ---------------- No (0)  Yes (1)\")\n",
    "print(f\"Actual No     {cm[0,0]:5}   {cm[0,1]:5}\")\n",
    "print(f\"Actual Yes    {cm[1,0]:5}   {cm[1,1]:5}\")\n",
    "print(f\"\\nAccuracy: {((cm[0,0] + cm[1,1]) / len(y_test)):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a99fc9",
   "metadata": {},
   "source": [
    "### 7,How does Gradient Boosting perform compared to Random Forest and Logistic Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c27f496c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 3: GRADIENT BOOSTING\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Model trained on 5,634 customers\n",
      "Tested on 1,409 customers\n",
      "\n",
      "AUC-ROC Score: 0.8335\n",
      "\n",
      "Confusion Matrix:\n",
      "---------------------Predicted\n",
      "------------------No (0)  Yes (1)\n",
      "Actual No       929     106\n",
      "Actual Yes      183     191\n",
      "\n",
      "Accuracy: 79.5%\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting (BEST MODEL)\n",
    "print(\"MODEL 3: GRADIENT BOOSTING\")\n",
    "print(\"--\" * 60)\n",
    "\n",
    "# Train the model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "gb_pred_prob = gb_model.predict_proba(X_test)[:, 1]\n",
    "gb_pred = gb_model.predict(X_test)\n",
    "\n",
    "# performance\n",
    "gb_auc = roc_auc_score(y_test, gb_pred_prob)\n",
    "print(f\"\\nModel trained on {len(X_train):,} customers\")\n",
    "print(f\"Tested on {len(X_test):,} customers\")\n",
    "print(f\"\\nAUC-ROC Score: {gb_auc:.4f}\")\n",
    "\n",
    "#confusion matrix\n",
    "cm = confusion_matrix(y_test, gb_pred)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"---------------------Predicted\")\n",
    "print(f\"------------------No (0)  Yes (1)\")\n",
    "print(f\"Actual No     {cm[0,0]:5}   {cm[0,1]:5}\")\n",
    "print(f\"Actual Yes    {cm[1,0]:5}   {cm[1,1]:5}\")\n",
    "print(f\"\\nAccuracy: {((cm[0,0] + cm[1,1]) / len(y_test)):.1%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2882e7c",
   "metadata": {},
   "source": [
    "### 8,Which model performs best overall, and why should we select it for churn prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a21bb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL COMPARISON SUMMARY\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "\n",
      "\n",
      "              Model  AUC-ROC  Accuracy Rank\n",
      "Logistic Regression 0.840758     0.800  1st\n",
      "      Random Forest 0.835676     0.796  2nd\n",
      "  Gradient Boosting 0.833455     0.795  3rd\n",
      "\n",
      "**********************************************************************\n",
      "Best: Logistic Regression\n",
      "AUC-ROC Score: 0.8408\n",
      "**********************************************************************\n",
      "  - Logistic Regression: 0.8408\n",
      "  - Random Forest: 0.8357 \n",
      "  - Gradient Boosting: 0.8335 \n"
     ]
    }
   ],
   "source": [
    "# Compare all models\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"|\" * 50)\n",
    "\n",
    "#  comparison table\n",
    "results = pd.DataFrame({'Model': ['Logistic Regression', 'Random Forest', 'Gradient Boosting'],'AUC-ROC': [lr_auc, rf_auc, gb_auc],'Accuracy': [0.80, 0.796, 0.795] })\n",
    "\n",
    "# Sort\n",
    "results = results.sort_values('AUC-ROC', ascending=False).reset_index(drop=True)\n",
    "results['Rank'] = ['1st', '2nd', '3rd']\n",
    "\n",
    "print(\"\\n\")\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"*\" * 70)\n",
    "print(f\"Best: {results.iloc[0]['Model']}\")\n",
    "print(f\"AUC-ROC Score: {results.iloc[0]['AUC-ROC']:.4f}\")\n",
    "print(\"*\" * 70)\n",
    "\n",
    "print(f\"  - Logistic Regression: {lr_auc:.4f}\")\n",
    "print(f\"  - Random Forest: {rf_auc:.4f} \")\n",
    "print(f\"  - Gradient Boosting: {gb_auc:.4f} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03d30468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Selected Model: Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "best_model = lr_model\n",
    "best_model_name = \"Logistic Regression\"\n",
    "print(f\"\\n Selected Model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb06d10",
   "metadata": {},
   "source": [
    "### 9,How do we save the best model for future customer risk predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "029a3f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  File: outputs/churn_model.pkl\n",
      "  Total features: 19\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "#Save model\n",
    "with open('../outputs/churn_model.pkl', 'wb') as f:pickle.dump(lr_model, f)\n",
    "print(f\"  File: outputs/churn_model.pkl\")\n",
    "# saving feature names\n",
    "feature_names = list(X.columns)\n",
    "with open('../outputs/feature_names.pkl', 'wb') as f:pickle.dump(feature_names, f)\n",
    "print(f\"  Total features: {len(feature_names)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0447dc5f",
   "metadata": {},
   "source": [
    "### 10,What is the business impact of customer churn, and how many high-risk customers can we identify?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ea34f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total customers analyzed: 7,043\n",
      "Actual churn count: 1,869\n",
      "Actual churn rate: 26.5%\n",
      "\n",
      "Average monthly charges: $64.76\n",
      "Monthly revenue at risk: $121,039.60\n",
      "Annual revenue at risk: $1,452,475.24\n",
      "Annual revenue at risk (millions): $1.5M\n",
      "\n",
      "Model accuracy:\n",
      "High-risk customers identified: 436\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/Telco-Customer-Churn.csv')\n",
    "total_customers = len(df)\n",
    "print(f\"\\nTotal customers analyzed: {total_customers:,}\")\n",
    "churned = (df['Churn'] == 'Yes').sum()\n",
    "churn_rate = (churned / total_customers) * 100\n",
    "print(f\"Actual churn count: {churned:,}\")\n",
    "print(f\"Actual churn rate: {churn_rate:.1f}%\")\n",
    "avg_monthly = df['MonthlyCharges'].mean()\n",
    "print(f\"\\nAverage monthly charges: ${avg_monthly:.2f}\")\n",
    "revenue_at_risk_monthly = churned * avg_monthly\n",
    "revenue_at_risk_annual = revenue_at_risk_monthly * 12\n",
    "print(f\"Monthly revenue at risk: ${revenue_at_risk_monthly:,.2f}\")\n",
    "print(f\"Annual revenue at risk: ${revenue_at_risk_annual:,.2f}\")\n",
    "print(f\"Annual revenue at risk (millions): ${revenue_at_risk_annual/1_000_000:.1f}M\")\n",
    "try:\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    acc = accuracy_score(y_test, lr_pred)\n",
    "    print(f\"\\nModel accuracy: {(acc*100):.1f}%\")\n",
    "except:\n",
    "    print(f\"\\nModel accuracy:\")\n",
    "\n",
    "try:\n",
    "    risk_df = pd.read_csv('../outputs/high_risk_action_list.csv')\n",
    "    high_risk_count = len(risk_df)\n",
    "    print(f\"High-risk customers identified: {high_risk_count:,}\")\n",
    "except:\n",
    "    print(\" High-risk file not found \")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
